{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Spam Classification with SVMs \n",
    "## Part 1: Email Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import key libraries (remember to pip install numpy etc. first)\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing sample email (emailSample1.txt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nPreprocessing sample email (emailSample1.txt)\\n')\n",
    "PATH=\"./data/\"\n",
    "DATA=\"emailSample1.txt\"\n",
    "\n",
    "with open(f'{PATH}{DATA}', 'r') as email:\n",
    "    file_contents=email.read()#.replace('\\n', '')\n",
    "    email.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVocabList():\n",
    "    #GETVOCABLIST reads the fixed vocabulary list in vocab.txt and returns a\n",
    "    #cell array of the words\n",
    "    #   vocabList = GETVOCABLIST() reads the fixed vocabulary list in vocab.txt \n",
    "    #   and returns a cell array of the words in vocabList.\n",
    "    DATA=\"vocab.txt\"\n",
    "    vocablist = []\n",
    "    with open(f'{PATH}{DATA}', 'r') as vocabfile:\n",
    "        lines=vocabfile.readlines()#.replace('\\n','')\n",
    "        vocabfile.close()\n",
    "    for line in lines:\n",
    "        vocablist += [line[line.find('\\t')+1:-1]]\n",
    "    return np.array(vocablist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'ab', 'abil', ..., 'zdnet', 'zero', 'zip'], dtype='<U40')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getVocabList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regexprep (email, reg, repl):\n",
    "    regex = re.compile(reg, re.IGNORECASE)\n",
    "    email_contents, count = regex.subn(repl, email)\n",
    "    return email_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processEmail(email_contents, show=False):\n",
    "    #PROCESSEMAIL preprocesses a the body of an email and\n",
    "    #returns a list of word_indices\n",
    "    #   word_indices = PROCESSEMAIL(email_contents) preprocesses\n",
    "    #   the body of an email and returns a list of indices of the\n",
    "    #   words contained in the email.\n",
    "    #\n",
    "\n",
    "    if show:\n",
    "        print (f\"=======ORIGINAL EMAIL BEG==========\\n{email_contents}\\n=======ORIGINAL EMAIL END==========\")\n",
    "    # Load Vocabulary\n",
    "    vocabList = getVocabList()\n",
    "    \n",
    "    # Init return value\n",
    "    word_indices = np.array([])\n",
    "\n",
    "    # ========================== Preprocess Email ===========================\n",
    "\n",
    "    # Find the Headers ( \\n\\n and remove )\n",
    "    # Uncomment the following lines if you are working with raw emails with the\n",
    "    # full headers\n",
    "\n",
    "    # hdrstart = strfind(email_contents, ([char(10) char(10)]));\n",
    "    # email_contents = email_contents(hdrstart(1):end);\n",
    "\n",
    "    # Lower case\n",
    "    email_contents = email_contents.lower()\n",
    "\n",
    "    # Strip all HTML\n",
    "    # Looks for any expression that starts with < and ends with > and replace\n",
    "    # and does not have any < or > in the tag it with a space\n",
    "\n",
    "    email_contents = regexprep(email_contents, r'<[^<>]+>', ' ')\n",
    "\n",
    "    # Handle Numbers\n",
    "    # Look for one or more characters between 0-9\n",
    "    email_contents = regexprep(email_contents, r'[0-9]+', 'number')\n",
    "\n",
    "    # Handle URLS\n",
    "    # Look for strings starting with http:// or https://\n",
    "\n",
    "    email_contents = regexprep(email_contents, r'(http|https)://[^\\s]*', 'httpaddr')\n",
    "\n",
    "    # Handle Email Addresses\n",
    "    # 3 Look for strings with @ in the middle\n",
    "    email_contents = regexprep(email_contents, r'[^\\s]+@[^\\s]+', 'emailaddr');\n",
    "\n",
    "    # Handle $ sign\n",
    "    email_contents = regexprep(email_contents, r'[$]+', 'dollar');\n",
    "\n",
    "    # Output the email to screen as well\n",
    "    if show:\n",
    "        print (f\"=======PROCESSED EMAIL BEG==========\")\n",
    "\n",
    "    # Process file\n",
    "    l = 0\n",
    "    \n",
    "    # Tokenize and also get rid of any punctuation\n",
    "    regex = re.compile(r'[][ @$/#.-:&*+=?!(){},''\">_<;%\\n\\t]', re.IGNORECASE)\n",
    "    string_splits = re.split(regex, email_contents) \n",
    "\n",
    "    from nltk.stem import PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "    count = 0\n",
    "\n",
    "    for str in string_splits:\n",
    "\n",
    "        # Remove any non alphanumeric characters\n",
    "        str = regexprep(str, '[^a-zA-Z0-9]', '')\n",
    "\n",
    "        # Stem the word\n",
    "        # (the porterStemmer sometimes has issues, so we use a try catch block)\n",
    "        str=ps.stem(str)\n",
    "\n",
    "        # Skip the word if it is too short\n",
    "        if len(str) < 1:\n",
    "           continue\n",
    "\n",
    "        #wordindx = find(ismember(vocabList, str)==1)\n",
    "        wordindx = np.argwhere(np.in1d(vocabList, str)).ravel()\n",
    "        #print(f'word_indices{word_indices} \\n wordindx{wordindx}')\n",
    "\n",
    "        if len(wordindx)>0:\n",
    "            word_indices = np.r_[word_indices, wordindx]\n",
    "\n",
    "        # Print to screen, ensuring that the output lines are not too long\n",
    "        if show:\n",
    "            if (l + len(str) + 1) > 70:\n",
    "                print()\n",
    "                l = 0\n",
    "            print(f'{str} ', end='')\n",
    "            l = l + len(str) + 1\n",
    "    if show:\n",
    "        print (f\"\\n=======PROCESSED EMAIL END==========\")\n",
    "        print (word_indices.astype(int))\n",
    "\n",
    "    return word_indices.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======ORIGINAL EMAIL BEG==========\n",
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n",
      "=======ORIGINAL EMAIL END==========\n",
      "=======PROCESSED EMAIL BEG==========\n",
      "anyon know how much it cost to host a web portal well it depend on \n",
      "how mani visitor your expect thi can be anywher from less than number \n",
      "buck a month to a coupl of dollarnumb you should checkout httpaddr or \n",
      "perhap amazon ecnumb if your run someth big to unsubscrib yourself \n",
      "from thi mail list send an email to emailaddr \n",
      "=======PROCESSED EMAIL END==========\n",
      "[  85  915  793 1076  882  369 1698  789 1821 1830  882  430 1170  793\n",
      " 1001 1894  591 1675  237  161   88  687  944 1662 1119 1061 1698  374\n",
      " 1161  478 1892 1509  798 1181 1236  809 1894 1439 1546  180 1698 1757\n",
      " 1895  687 1675  991  960 1476   70  529 1698  530]\n"
     ]
    }
   ],
   "source": [
    "word_indices  = processEmail(file_contents, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(getVocabList())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emailFeatures(word_indices):\n",
    "    #EMAILFEATURES takes in a word_indices vector and produces a feature vector\n",
    "    #from the word indices\n",
    "    #   x = EMAILFEATURES(word_indices) takes in a word_indices vector and\n",
    "    #   produces a feature vector from the word indices.\n",
    "\n",
    "    # Total number of words in the dictionary\n",
    "    n = len(getVocabList())\n",
    "    \n",
    "    # binary feature vector\n",
    "    x = np.zeros((n, 1))\n",
    "    x[word_indices]=1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature vector: 1899\n",
      "Number of non-zero entries: 44\n",
      "Program paused. Press enter to continue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = emailFeatures(word_indices)\n",
    "\n",
    "# Print Stats\n",
    "print(f'Length of feature vector: {len(features)}')\n",
    "print(f'Number of non-zero entries: {np.sum(features > 0)}')\n",
    "print('Program paused. Press enter to continue.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Train Linear SVM for Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear SVM (Spam Classification)\n",
      "\n",
      "(this may take 1 to 2 minutes) ...\n",
      "\n",
      "Training Accuracy: 99.825\n"
     ]
    }
   ],
   "source": [
    "# import csv data\n",
    "PATH=\"./data/\"\n",
    "DATA=\"spamTrain.mat\"\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat(f'{PATH}{DATA}') # training data stored in arrays X, y\n",
    "X = mat['X']\n",
    "y = mat['y']\n",
    "\n",
    "print('\\nTraining Linear SVM (Spam Classification)\\n')\n",
    "print('(this may take 1 to 2 minutes) ...\\n')\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "C = 0.1\n",
    "#model = svmTrain(X, y, C, @linearKernel);\n",
    "clf = svm.SVC(C, kernel='linear', tol=1e-3, max_iter=10000) # note using svm built in linear kernel\n",
    "clf.fit(X, y.ravel())  \n",
    "\n",
    "p = clf.predict(X)\n",
    "#p = svmPredict(model, X);\n",
    "\n",
    "print(f'Training Accuracy: {np.mean((p.ravel() == y.ravel())*1.0) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Test Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv data\n",
    "PATH=\"./data/\"\n",
    "DATA=\"spamTest.mat\"\n",
    "\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat(f'{PATH}{DATA}') # training data stored in arrays X, y\n",
    "Xtest = mat['Xtest']\n",
    "ytest = mat['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the trained Linear SVM on a test set ...\n",
      "\n",
      "Test Accuracy: 98.9\n"
     ]
    }
   ],
   "source": [
    "print('\\nEvaluating the trained Linear SVM on a test set ...\\n')\n",
    "\n",
    "p = clf.predict(Xtest)\n",
    "\n",
    "print(f'Test Accuracy: {np.mean((p.ravel() == ytest.ravel())*1.0) * 100}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Top Predictors of Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " our            (0.500614)\n",
      " click          (0.465916)\n",
      " remov          (0.422869)\n",
      " guarante       (0.383622)\n",
      " visit          (0.367710)\n",
      " basenumb       (0.345064)\n",
      " dollar         (0.323632)\n",
      " will           (0.269724)\n",
      " price          (0.267298)\n",
      " pleas          (0.261169)\n",
      " most           (0.257298)\n",
      " nbsp           (0.253941)\n",
      " lo             (0.253467)\n",
      " ga             (0.248297)\n",
      " hour           (0.246404)\n"
     ]
    }
   ],
   "source": [
    "idx = np.argsort(clf.coef_.ravel())[::-1] # Need ::-1 as want descending, so need to invert argsort result\n",
    "vocab = getVocabList()\n",
    "vocab[idx[0:10]]\n",
    "\n",
    "weight = clf.coef_.ravel()[idx]\n",
    "\n",
    "for i in range(15):\n",
    "    print(f' {vocab[idx[i]]:15}({weight[i]:.6f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Try Your Own Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing sample email (emailSample1.txt)\n",
      "\n",
      "=======ORIGINAL EMAIL BEG==========\n",
      "Do You Want To Make $1000 Or More Per Week?\n",
      "\n",
      " \n",
      "\n",
      "If you are a motivated and qualified individual - I \n",
      "will personally demonstrate to you a system that will \n",
      "make you $1,000 per week or more! This is NOT mlm.\n",
      "\n",
      " \n",
      "\n",
      "Call our 24 hour pre-recorded number to get the \n",
      "details.  \n",
      "\n",
      " \n",
      "\n",
      "000-456-789\n",
      "\n",
      " \n",
      "\n",
      "I need people who want to make serious money.  Make \n",
      "the call and get the facts. \n",
      "\n",
      "Invest 2 minutes in yourself now!\n",
      "\n",
      " \n",
      "\n",
      "000-456-789\n",
      "\n",
      " \n",
      "\n",
      "Looking forward to your call and I will introduce you \n",
      "to people like yourself who\n",
      "are currently making $10,000 plus per week!\n",
      "\n",
      " \n",
      "\n",
      "000-456-789\n",
      "\n",
      "\n",
      "\n",
      "3484lJGv6-241lEaN9080lRmS6-271WxHo7524qiyT5-438rjUv5615hQcf0-662eiDB9057dMtVl72\n",
      "\n",
      "\n",
      "=======ORIGINAL EMAIL END==========\n",
      "=======PROCESSED EMAIL BEG==========\n",
      "do you want to make dollarnumb or more per week if you are a motiv \n",
      "and qualifi individu i will person demonstr to you a system that will \n",
      "make you dollarnumb number per week or more thi is not mlm call our \n",
      "number hour prerecord number to get the detail numbernumbernumb i \n",
      "need peopl who want to make seriou money make the call and get the \n",
      "fact invest number minut in yourself now numbernumbernumb look \n",
      "forward to your call and i will introduc you to peopl like yourself \n",
      "who are current make dollarnumb number plu per week numbernumbernumb \n",
      "numberljgvnumbernumberleannumberlrmsnumbernumberwxhonumberqiytnumbernumberrjuvnumberhqcfnumbernumbereidbnumberdmtvlnumb \n",
      "=======PROCESSED EMAIL END==========\n",
      "[ 470 1892 1808 1698  996  478 1181 1063 1230 1826  809 1892 1069   73\n",
      " 1345  836 1851 1241 1698 1892 1630 1664 1851  996 1892  478 1119 1230\n",
      " 1826 1181 1063 1675  876 1112  233 1190 1119  791 1119 1698  707 1665\n",
      "  439 1092 1229 1843 1808 1698  996 1489  996 1665  233   73  707 1665\n",
      "  607  868 1119 1047  824 1895 1116  975  675 1698 1894  233   73 1851\n",
      "  866 1892 1698 1229  955 1895 1843  386  996  478 1119 1264 1230 1826]\n",
      "\n",
      "\n",
      "======SPAM CLASSIFIER=========\n",
      "Processed spamSample1.txt\n",
      "\n",
      "Spam Classification: [1]\n",
      "\n",
      "(1 indicates spam, 0 indicates not spam)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nPreprocessing sample email (emailSample1.txt)\\n')\n",
    "PATH=\"./data/\"\n",
    "DATA=\"spamSample1.txt\"\n",
    "\n",
    "with open(f'{PATH}{DATA}', 'r') as email:\n",
    "    file_contents=email.read()#.replace('\\n', '')\n",
    "    email.close()\n",
    "\n",
    "\n",
    "word_indices  = processEmail(file_contents, show=True)\n",
    "x = emailFeatures(word_indices).T\n",
    "p = clf.predict(x)\n",
    "\n",
    "print(f'\\n\\n======SPAM CLASSIFIER=========\\nProcessed {DATA}\\n\\nSpam Classification: {p}\\n')\n",
    "print('(1 indicates spam, 0 indicates not spam)\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
